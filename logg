Question:
1.Sub-process /usr/bin/dpkg returned an error code (1)
: sudo mv /var/lib/dpkg/info /var/lib/dpkg/info_old  将现在文件夹更名
  sudo mkdir /var/lib/dpkg/info                      新建文件夹
  sudo apt-get update                                更新库
  sudo apt-get -f install                            强制删除
  sudo mv /var/lib/dpkg/info/* /var/lib/dpkg/info_old更新的库移动到老的文件夹种
  sudo rm-rf /var/lib/dpkg/info                      删除自己之前建立的文件夹
  sudo mv /var/lib/dpkg/info_old /var/lib/dpkg/info  名字更换回来
2.File "/usr/bin/pip", line 9, in <module>
    from pip import main
  ImportError: cannot import name main
:将
  from pip import main
  if __name__ == '__main__':
    sys.exit(main())
  修改为：
  from pip import __main__
  if __name__ == '__main__':
    sys.exit(__main__._main())
3.重装完Ubuntu系统，电脑非常卡，每个页面都像放PPT一样
：需要装驱动
4.处女党清理文件把Ubuntu/usr文件夹下一个文件删除，瞬间大爆炸，/usr文件夹下所有文件一个个跟着消失，终端不能用，不能上网
  文件夹变灰，现在不敢动，害怕一动自己写的代码全军淹没，你现在需要做的是：
：a：制作一个Ubuntu的启动U盘
  b：插入电脑U盘启动，try Ubuntu （因为这时候你发现一个computer，一个很大的硬盘，你已傻傻分不清U盘在哪里）
  c：用另一个U盘把你需要的数据COPY出来（sb如我以为computer 就是U盘，然后把数据copy到这里，重装完发现数据没了，辛辛苦苦做的几个月的东西，已经哭晕在厕所）
  d：一定要确认你的数据是否完好无损 （一定要）
  e：重装系统（不要尝试把try Ubuntu 下的/usr 文件夹 copy 到你之前删除的 /usr 下去，因为没用）
5.pip install --user Cython
Could not find a version that satisfies the requirement Cpythpn
:如果确定资源里有该包一般是网络原因，被墙了，或者什么，翻墙完美解决
6.用自己的数据训练 MobileNet SSD
a:安装ObjectAPI
  有些转换需要老版本，可以小窗我
  按着网管教程https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md#dependencies 安装
  有的时候需要翻墙哦！
  1.新版本官网git https://github.com/tensorflow/models.git 旧版本这里link
  2.sudo apt-get install protobuf-compiler python-pil python-lxml python-tk
    pip install --user Cython（需要翻墙）
    pip install --user contextlib2
    pip install --user jupyter
    pip install --user matplotlib
  3.coco API installation(若不用coco的可以不安装这个)
    git clone https://github.com/cocodataset/cocoapi.git
    cd cocoapi/PythonAPI
    make
    cp -r pycocotools <刚才下载的path>/models/research/
  4.在<刚才下载的path>/models/research/执行
    wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip
    unzip protobuf.zip
    ./bin/protoc object_detection/protos/*.proto --python_out=.
  5.Add Libraries to PYTHONPATH
    在<刚才下载的path>/models/research/执行 export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim
    或者 sudo gedit ~/.bashrc 下面添加
    export PYTHONPATH=$PYTHONPATH:<刚才下载的path>/models/research:<刚才下载的path>/models/research/slim
  6.测试：在<刚才下载的path>/models/research 执行
    python object_detection/builders/model_builder_test.py
    正确的输出应为：
    ----------------------------------------------------------------------
    Ran 18 tests in 0.043s
    OK
    如果错误5没有装好。
b：制作自己的数据集：
  1.labelImg进行标注图片（可以是voc，可以是yolo，若voc省去步骤2）
  2.txt->xml
    python txt_xml.py
  3.xml->csv
    修改路径 执行 python xml_to_csv.py
  4.csv->tfRecords
    python generate_tfrecord.py --csv_input=/home/sy/data/work/StandardCVSXImages/pupils_test.csv --output_path=pupils_test.record
c:准备配置文件和模型
  1.生成pbtxt文件
    item {
      id:1
      name:'pupils'
    }
  2.修改model，以ssd_mobilenet_v1_coco.config为例做如下修改
      model {
        ssd {
        num_classes: 1 #类别数
        box_coder {
          faster_rcnn_box_coder {
            y_scale: 10.0
            x_scale: 10.0
            height_scale: 5.0
            width_scale: 5.0
          }
        }
        matcher {
          argmax_matcher {
            matched_threshold: 0.5
            unmatched_threshold: 0.5
            ignore_thresholds: false
            negatives_lower_than_unmatched: true
            force_match_for_each_row: true
          }
        }
        similarity_calculator {
          iou_similarity {
          }
        }
        anchor_generator {
          ssd_anchor_generator {
            num_layers: 6
            min_scale: 0.2
            max_scale: 0.95
            aspect_ratios: 1.0
            # aspect_ratios: 2.0
            # aspect_ratios: 0.5
            # aspect_ratios: 3.0
            # aspect_ratios: 0.3333
          }
        }
        image_resizer {
          fixed_shape_resizer {
            height: 300
            width: 300
          }
        }
        box_predictor {
          convolutional_box_predictor {
            min_depth: 0
            max_depth: 0
            num_layers_before_predictor: 0
            use_dropout: false
            dropout_keep_probability: 0.8
            kernel_size: 1
            box_code_size: 4
            apply_sigmoid_to_scores: false
            conv_hyperparams {
              activation: RELU_6,
              regularizer {
                l2_regularizer {
                  weight: 0.00004
                }
              }
              initializer {
                truncated_normal_initializer {
                  stddev: 0.03
                  mean: 0.0
                }
              }
              batch_norm {
                train: true,
                scale: true,
                center: true,
                decay: 0.9997,
                epsilon: 0.001,
              }
            }
          }
        }
        feature_extractor {
          type: 'ssd_mobilenet_v1'
          min_depth: 16
          depth_multiplier: 0.75
          conv_hyperparams {
            activation: RELU_6,
            regularizer {
              l2_regularizer {
                weight: 0.00004
              }
            }
            initializer {
              truncated_normal_initializer {
                stddev: 0.03
                mean: 0.0
              }
            }
            batch_norm {
              train: true,
              scale: true,
              center: true,
              decay: 0.9997,
              epsilon: 0.001,
            }
          }
        }
        loss {
          classification_loss {
            weighted_sigmoid {
            }
          }
          localization_loss {
            weighted_smooth_l1 {
            }
          }
          hard_example_miner {
            num_hard_examples: 3000
            iou_threshold: 0.99
            loss_type: CLASSIFICATION
            max_negatives_per_positive: 3
            min_negatives_per_image: 0
          }
          classification_weight: 1.0
          localization_weight: 1.0
        }
        normalize_loss_by_num_matches: true
        post_processing {
          batch_non_max_suppression {
            score_threshold: 1e-8
            iou_threshold: 0.6
            max_detections_per_class: 100
            max_total_detections: 100
          }
          score_converter: SIGMOID
        }
       }
      }

train_config: {
  batch_size: 1
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.001 # 刚开始训练的时候的学习率
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }
  # Note: The below line limits the training process to 200K steps, which we
  # empirically found to be sufficient enough to train the pets dataset. This
  # effectively bypasses the learning rate schedule (the learning rate will
  # never decay). Remove the below line to train indefinitely.
  num_steps: 200000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: "/home/sy/data/work/StandardCVSXImages/pupils_train.record"
  }
  label_map_path: "/home/sy/data/work/StandardCVSXImages/pupils.pbtxt"
}

eval_config: {
  num_examples: 8000
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: "/home/sy/data/work/StandardCVSXImages/pupils_test.record"
  }
  label_map_path: "/home/sy/data/work/StandardCVSXImages/pupils.pbtxt"
  shuffle: false
  num_readers: 1
}
d:开始训练：在models/research/object_detection/下执行
   python legacy/train.py --logtostderr --train_dir=training/ --pipeline_config_path=/home/sy/data/work/StandardCVSXImages/ssd_mobilenet_v1_coco.config
   python3 object_detection/model_main.py --pipeline_config_path=/home/sy/data/work/StandardCVSXImages/ssd_mobilenet_v1_coco.config --model_dir=/home/sy/code/project/models/research/object_detection/training/ --num_train_steps=50000 --num_eval_step=2000 --alsologtostdeer
           两个坑：
           1.`train_dir` is missing
           answer:--train_dir=training/ 这句必须用相对路径
           2.tensorflow.python.framework.errors_impl.NotFoundError
           answer:--pipeline_config_path=/home/sy/data/work/StandardCVSXImages/ssd_mobilenet_v1_coco.config "="后面紧跟${dir} 不能有空
           ref： https://github.com/tensorflow/models/issues/2984
           3.ImportError: /home/sy/code/project/models/research/pycocotools/_mask.so: undefined symbol: _Py_ZeroStruct
             cocoapi 安装好，然后复制到 research 中
             进入/home/user/models/research/目录，　执行cp -r /home/user/cocoapi/PythonAPI/pycocotools ./
           4.
            https://github.com/tensorflow/models/issues/5391#issuecomment-431676300

e:用models/research/object_detection/的export_inference_graph转换为.pb文件
   python export_inference_graph.py --input_type=image_tensor --pipeline_config_path=/home/sy/code/project/models/research/object_detection/training/pipeline.config --trained_checkpoint_prefix=/home/sy/code/project/models/research/object_detection/training/model.ckpt-9286 --output_directory=/home/sy/code/project/models/research/object_detection/training/log/

f:测试
  1.执行
    修改文件中的路径文件，在models/research/ 下执行
    python object_detection.py
  2.遇到问题
   2.1：No module named '_tkinter'
   answer:sudo apt install python3-tk
          https://blog.csdn.net/blueheart20/article/details/78763208
   2.2:测试的时候一个框也没有检测出来，并且训练的时候loss抖动量较大
   answer:根本原因是数据量太小;无法改变数据量的时候可以尝试下调大batchsize，或者调小学习率
   2.3:pycharm中导入tensorflow 经常遇到“failed to run cuBLAS routine cublasSgemm_v2: CUBLAS_STATUS_EXECUTION_FAILED”
   answer:feel relax and reboot the pycharm
7. 搭建android环境：
 a：下载android-studio，jdk，android-ndk 安装包
 b：安装并配置jdk
   b.1:解压jdr
   b.2:配置环境变量：
        export JAVA_HOME=/home/sy/software/jdk1.8.0_171
        export JRE_HOME=${JAVA_HOME}/jre
        export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
        export PATH=${JAVA_HOME}/bin:$PATH
   b.3:验证 重新开个终端
        java -version 能正确输出version即可
 c：install android-studio:
   c.1: bash android-studio/bin/studio.sh
   c.2: 按着默认状态继续执行
   c.3: 设置成可以终端启动 参考 https://blog.csdn.net/qq_31119155/article/details/80041567
 d：导入要运行工程
 e：常见问题：
   e.1:Could not find com.android.tools.build:aapt2:3.2.0-4818971
     answer:最上面那一级的build.gradle(project) 中 allprojects{ }
            allprojects {
                repositories {
                    jcenter()
                    google() # 添加上去
                }
            }
   e.2:
   e.3:
   e.4:
 8.安装SNPE：
   a: download https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk
   b：setup the SDK
     b.1:sudo apt-get install python-dev python-matplotlib python-numpy python-protobuf python-scipy python-skimage python-sphinx wget zip
     b.2:source ~/snpe-sdk/bin/dependencies.sh
     b.3:source ~/snpe-sdk/bin/check_python_depends.sh
   c:config SDK
    c.1: sudo gedit ~/.bashrc
         export export ANDROID_NDK_ROOT=/home/sy/software/android-ndk-r16b
         source ~/.bashrc
    c.2:cd ~/snpe-sdk
        source ./bin/envsetup.sh -t /home/sy/.local/lib/python2.7/site-packages/tensorflow
   d:Download the models and convert them to .dlc file
   e: build the example android app https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk/getting-started




