# 卷积层
  
    卷积层是卷积神经网络种的基础网络，甚至在网络最后起分类作用的全连接层也是由卷积操作代替的;
    卷积操作是一种局部操作，通多一定大小的卷积核作用于局部图像区域获得图像的局部信息;
    事实上，卷积网路中的卷积核参数是通过网络训练学习到的，可以学到横向、纵向、任意角度、颜色、纹理、形状等众多模式的卷积核（滤波器），通过组合
    这些滤波器以及网络的后续操作，基本、一般的模式会逐渐被抽象为具有高层语义“概念”表示，并以此对应到具体的样本类别中。
   ![](pic/juanjigongsi.png)
     
     由上式可以看出，权重对不同位置的所有输入是一样的，这便是卷积层的“权值共享”，当然有时候还会在y上输入偏置项。在误差反向传播时可针对该层权重和偏置项分别设置随机梯度下降的学习率。
     当然根据实际情况，也可将某层偏置项设置为0,或者学习率设置为0,以起到固定该层偏置或权重的作用。
    
# 汇合层的功效
1. 特征不变性

       汇合操作使模型更关注是否存在特征而不是具体的位置; 
       使特征学习包含某种程度的自由度，能容忍一些特征微小的位移;
2. 特征降维

       汇合层的每个元素对应于原输入数据的一个子区域，因此汇合层相当于空间范围做了维度的约减，从而使得模型可以抽取更广泛的特征;
       减少下一层的输入大小，进而减小计算量和参数个数;
3. 防止过拟合

# 激活函数

    模拟了生物神经元特性：接受一组信号并产生输出，当神经元获得的输入信号累计效果超过一个阈值，神经元处于兴奋状态，否则抑制;
| 激活函数  | 缺点 |  优点  | 
|:--------|:-------|:-------| 
| sigmoid| "饱和效应"|可以模拟生物神经元受刺激过程|
|relu|    | 消除饱和效应;|
|    |    |收敛速度加快; | 

# 全连接层

    如果说卷积层、汇合层和激活函数层等操作是将原始数据映射到隐层特征空间的话，全连接层则起到将学到的特征表示映射到样本的标记空间的作用。
  
# 目标函数

    目标函数的作用是用来衡量全连接层做出预测和真实样本标记之间的误差;
 |目标函数|应用范围 |
 |:-----|:-------|
 |交叉熵损失函数|分类问题|
 |l2损失函数|回归问题| 